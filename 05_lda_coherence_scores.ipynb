{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f537e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ab3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_name = \"data\"\n",
    "models_dir_name = \"models\"\n",
    "lda_dir_name = \"lda\"\n",
    "lda_log_dir = \"lda_topics\"\n",
    "documents_dir_name = \"corpus\"\n",
    "documents_file_name = \"lemmatized_lifestyle_documents.json\"\n",
    "lifestye_stopwords_file_name = \"lifestyle_stop_words_4_lda.json\"\n",
    "documents_file = os.path.join(data_dir_name, documents_dir_name, documents_file_name)\n",
    "lda_dir_path = os.path.join(data_dir_name, models_dir_name, lda_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe58d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(documents_file, \"r\") as file:\n",
    "    lifestyle_documents = json.load(file)\n",
    "\n",
    "count_vectorizer_file_name = \"count_vectorizer.pkl\"\n",
    "doc_term_matrix_file_name = \"doc_term_matrix.pkl\"\n",
    "\n",
    "# Load an LDA model (or LDA models)\n",
    "lda_models = {}\n",
    "\n",
    "for item in os.listdir(lda_dir_path):\n",
    "    if item.startswith(\"lda_\") and item.endswith(\"_topics.pkl\"):\n",
    "        n_topics_match = re.search(r\"lda_(\\d+)_topics\\.pkl\", item)\n",
    "        if n_topics_match:\n",
    "            n_topics = int(n_topics_match.group(1))\n",
    "            lda_models[n_topics] = joblib.load(os.path.join(lda_dir_path, item))\n",
    "\n",
    "lda_models = dict(sorted(lda_models.items(), key=lambda item: item[0], reverse=False))\n",
    "\n",
    "# Load the vectorizer\n",
    "vectorizer = joblib.load(os.path.join(lda_dir_path, count_vectorizer_file_name))\n",
    "\n",
    "# Load the doc-term matrix\n",
    "doc_term_matrix = joblib.load(os.path.join(lda_dir_path, doc_term_matrix_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea009863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 'lifestyle_stop-words'\n",
    "stopwords_path = os.path.join(data_dir_name, models_dir_name, lda_dir_name, lifestye_stopwords_file_name)\n",
    "with open(stopwords_path, \"r\") as file:\n",
    "    lifestye_stopwords = json.load(file)\n",
    "\n",
    "# And removing the \"lifestyle_stop_words\" from the lemmatized texts for consitency:\n",
    "lifestyle_tokens = [[item for item in document.split() if item not in lifestye_stopwords] for document in lifestyle_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([item for sublist in [sublist for sublist in lifestyle_tokens] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98885e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mimicing CountVectorizer's vocabulary inside a Gensim Dictionary\n",
    "to be able to use sklearn LDA models to get coherence scores\n",
    "\"\"\"\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "id2word = Dictionary()\n",
    "id2word.token2id = {word: i for i, word in enumerate(feature_names)}\n",
    "id2word.id2token = {i: word for word, i in id2word.token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a340d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimic a gensim lda model using the data from an lda model and count_vectorizer's vocab\n",
    "import numpy as np\n",
    "\n",
    "class SklearnLdaGensimWrapper:\n",
    "    def __init__(self, sklearn_lda_model, feature_names, id2word):\n",
    "        self.num_topics = sklearn_lda_model.n_components\n",
    "        self.feature_names = feature_names\n",
    "        self.id2word = id2word\n",
    "        self.topic_term_matrix = sklearn_lda_model.components_\n",
    "\n",
    "    def show_topic(self, topicid, topn=10):\n",
    "        topic = self.topic_term_matrix[topicid]\n",
    "        top_indices = topic.argsort()[::-1][:topn]\n",
    "        return [(self.feature_names[i], topic[i]) for i in top_indices]\n",
    "\n",
    "    def get_topics(self):\n",
    "        return self.topic_term_matrix / self.topic_term_matrix.sum(axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def batch_coherence_score(lda_model, feature_names, id2word, texts, topn=25):\n",
    "    wrapper = SklearnLdaGensimWrapper(\n",
    "        sklearn_lda_model=lda_model,\n",
    "        feature_names=feature_names,\n",
    "        id2word=id2word\n",
    "    )\n",
    "\n",
    "    topics = [[word for word, _ in wrapper.show_topic(i, topn=topn)]\n",
    "              for i in range(wrapper.num_topics)]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topics,\n",
    "        texts=texts,\n",
    "        dictionary=id2word,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "\n",
    "    score = coherence_model.get_coherence()\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_coherence_scores_top25 = {}\n",
    "for n_topics, model in lda_models.items():\n",
    "    score = batch_coherence_score(\n",
    "        lda_model=model,\n",
    "        feature_names=feature_names,\n",
    "        id2word=id2word,\n",
    "        texts=lifestyle_tokens,\n",
    "        topn=25\n",
    "    )\n",
    "    sk_coherence_scores_top25[n_topics] = score\n",
    "    sk_coherence_scores_top25 = dict(sorted(sk_coherence_scores_top25.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "with open(os.path.join(lda_dir_path, \"sk_coherence_scores_top25.json\"), \"w\") as file:\n",
    "    json.dump(sk_coherence_scores_top25, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "125c1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading 'fake' gensim models\n",
    "(models fitted using id2word based on vount vectorizer's vocab)\n",
    "\"\"\"\n",
    "gensim_fake_lda_models = {}\n",
    "\n",
    "for item in os.listdir(lda_dir_path):\n",
    "    if item.startswith(\"gensim_fake_lda_\") and item.endswith(\"_topics.pkl\"):\n",
    "        n_topics_match = re.search(r\"gensim_fake_lda_(\\d+)_topics\\.pkl\", item)\n",
    "        if n_topics_match:\n",
    "            n_topics = int(n_topics_match.group(1))\n",
    "            gensim_fake_lda_models[n_topics] = joblib.load(os.path.join(lda_dir_path, item))\n",
    "\n",
    "gensim_fake_lda_models = dict(sorted(gensim_fake_lda_models.items(), key=lambda item: item[0], reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "353fa186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's see coherence scores using\n",
    "(1) id2word built from count_vectorizer's vocab (inherited from doing coherence scores for sklearn models above) and\n",
    "(2) gensim models fitted using that vocab\n",
    "\"\"\"\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "gensim_fake_coherence_scores_top25 = {}\n",
    "\n",
    "for n_topics, model in gensim_fake_lda_models.items():\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=model,\n",
    "        texts=lifestyle_tokens,\n",
    "        dictionary=id2word,\n",
    "        coherence='c_v',\n",
    "        topn=25\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    gensim_fake_coherence_scores_top25[n_topics] = coherence_score\n",
    "    gensim_fake_coherence_scores_top25 = dict(sorted(gensim_fake_coherence_scores_top25.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "with open(os.path.join(lda_dir_path, \"gensim_fake_coherence_scores_top25.json\"), \"w\") as file:\n",
    "    json.dump(gensim_fake_coherence_scores_top25, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb22610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's see coherence scores using\n",
    "(1) id2word built built by gensim natively and\n",
    "(2) gensim models fitted using that vocab (\"true\" models)\n",
    "\"\"\"\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "id2word = Dictionary(lifestyle_tokens)\n",
    "id2word.filter_extremes(no_below=2, no_above=0.95)\n",
    "\n",
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad841690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"true\" gensim LDA models\n",
    "\n",
    "gensim_true_lda_models = {}\n",
    "\n",
    "for item in os.listdir(lda_dir_path):\n",
    "    if item.startswith(\"gensim_true_lda_\") and item.endswith(\"_topics.pkl\"):\n",
    "        n_topics_match = re.search(r\"gensim_true_lda_(\\d+)_topics\\.pkl\", item)\n",
    "        if n_topics_match:\n",
    "            n_topics = int(n_topics_match.group(1))\n",
    "            gensim_true_lda_models[n_topics] = joblib.load(os.path.join(lda_dir_path, item))\n",
    "\n",
    "gensim_true_lda_models = dict(sorted(gensim_true_lda_models.items(), key=lambda item: item[0], reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f52c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "gensim_true_coherence_scores_top25 = {}\n",
    "\n",
    "for n_topics, model in gensim_true_lda_models.items():\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=model,\n",
    "        texts=lifestyle_tokens,\n",
    "        dictionary=id2word,\n",
    "        coherence='c_v',\n",
    "        topn=25\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    gensim_true_coherence_scores_top25[n_topics] = coherence_score\n",
    "    gensim_true_coherence_scores_top25 = dict(sorted(gensim_true_coherence_scores_top25.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "with open(os.path.join(lda_dir_path, \"gensim_true_coherence_scores_top25.json\"), \"w\") as file:\n",
    "    json.dump(gensim_true_coherence_scores_top25, file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
